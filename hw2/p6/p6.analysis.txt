Alan Cham
HW2 P6

The raw resuts from the tests are reproduced below:

-------------------------------------------------------------------------
Making raw performance analysis results:
Top    : total runtime (ms)
Bottom : average runtime per iteration (ms)
-------------------------------------------------------------------------
     Iterations     Strategy 1     Stragegy 2     Strategy 3
   1.000000e+00         0.0430      2433.0850        78.2220
                        0.0430      2433.0850        78.2220

   1.000000e+01         0.2520      2432.5170        79.2480
                        0.0252       243.2517         7.9248

   1.000000e+02         1.7940      2427.5340        78.5670
                        0.0179        24.2753         0.7857

   1.000000e+03        16.9530      2426.4410        82.7740
                        0.0170         2.4264         0.0828

   1.000000e+04       167.9120      2452.7840       113.0070
                        0.0168         0.2453         0.0113

   1.000000e+05      1676.1150      2673.9370       412.0420
                        0.0168         0.0267         0.0041

   1.000000e+06     16800.2370      4884.9220      3414.9820
                        0.0168         0.0049         0.0034

   1.000000e+07    166258.8530     27174.4050     33230.9050
                        0.0166         0.0027         0.0033



Analysis: 
For small problem sizes, Strategy 1 greatly outperforms the other two; for
example, up to a problem size of 1000 iterations, Strategy 1 is still
five times faster than the next best, which is Strategy 3. However,
Strategy 1 basically holds the same marginal cost per iteration regardless
of the total number, whereas Strategy 2 and 3 both invest a large
amount of time for the initial iteration in exchange for making all
subsequent iterations much cheaper. It is interesting to observe that
Strategy 2's average time per iteration scales almost perfectly until input
size increases to around 1e5.

In theory, "marginal" cost per subsequent iteration should be:
>>  Strategy 1: O(log n_1 + log n_2 +...+ log n_k)
    This is because a log n_i binary search must occur for each ith array.

>>  Strategy 2: O(k)
    This is because it takes exactly k table lookups

>>  Strategy 3: O(k + log M_0)
    This is because it takes k-1 table lookups, but still requires an additional
    O(log M_0) for the initial binary search (where M_0 denotes the length of
    array M_0).

The data corroborates these expectations, since Strategy 1 is the slowest, and
Strategy 2 and 3 differ only by a small interval of 0.6 us per marginal iteration,
as shown when the problem size is 1e7. This would match expectations due to
the cost of the initial binary search in each Strategy 3 iteration.

